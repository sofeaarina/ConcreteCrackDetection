{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassificationConcreteCracks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNU4UQTEy9hUBoS5gABjmKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofeaarina/ConcreteCrackDetection/blob/main/ImageClassificationConcreteCracks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kYEfFWkiv0va"
      },
      "outputs": [],
      "source": [
        "#1. Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, cv2, datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications, layers\n",
        "import pathlib as path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Data preparation\n",
        "root_path = r\"\"\n",
        "data_dir = path.Path(root_path)\n",
        "\n",
        "SEED = 12345\n",
        "IMG_SIZE = (160,160)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    data_dir, validation_split=0.3, subset='training', seed=SEED, shuffle=True,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "val_dataset = keras.utils.image_dataset_from_directory(\n",
        "    data_dir, validation_split=0.3, subset='validation', seed=SEED, shuffle=True,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "mGSHAg91wU8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Further split validation dataset into validation-test split\n",
        "val_batches = tf.data.experimental.cardinality(val_dataset)\n",
        "test_dataset = val_dataset.take(val_batches//5)\n",
        "validation_dataset = val_dataset.skip(val_batches//5)"
      ],
      "metadata": {
        "id": "NhZYLi1qwbl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prefetch dataset for all 3 splits\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "pf_train = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "pf_validation = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "pf_test = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0H_ciprQwo7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Create data augmentation pipeline\n",
        "data_augmentation = keras.Sequential()\n",
        "data_augmentation.add(layers.RandomFlip('horizontal'))\n",
        "data_augmentation.add(layers.RandomRotation(0.2))"
      ],
      "metadata": {
        "id": "6OiSM_FlwriU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in pf_train.take(1):\n",
        "    first_image = images[0]\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image,0))\n",
        "        plt.imshow(augmented_image[0]/255.0)\n",
        "        plt.axis('off')\n"
      ],
      "metadata": {
        "id": "TqClck4rwti2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a layer for data preprocessing\n",
        "preprocess_input = applications.mobilenet_v2.preprocess_input\n",
        "#Create the base model by using MobileNetV2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "\n",
        "#Apply layer freezing\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "ZHSRN1oEwwob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create classification layer\n",
        "class_names = train_dataset.class_names\n",
        "nClass = len(class_names)\n",
        "\n",
        "global_avg_pooling = layers.GlobalAveragePooling2D()\n",
        "output_layer = layers.Dense(nClass, activation='softmax')\n"
      ],
      "metadata": {
        "id": "7DRB62mew2kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use functional API to construct the entire model\n",
        "inputs = keras.Input(shape=IMG_SHAPE)\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x)\n",
        "x = global_avg_pooling(x)\n",
        "outputs = output_layer(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "IrFZpnXZw50X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "WpedvNZ7w7x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "1qBVbaHgxAVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform model training\n",
        "EPOCHS = 100\n",
        "base_log_path = r\"\"\n",
        "log_path= os.path.join(base_log_path, datetime.datetime.now().strftime('%Y%m%d-%H%M%S') + '__Project_3')\n",
        "tb = keras.callbacks.TensorBoard(log_dir=log_path)\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "history = model.fit(pf_train, validation_data=pf_validation, epochs=EPOCHS, callbacks=[es,tb])\n"
      ],
      "metadata": {
        "id": "YqmhfKWPxBIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deploy model to make prediction\n",
        "test_loss, test_accuracy = model.evaluate(pf_test)\n",
        "print('---------------------Test Result---------------------')\n",
        "print(f'Loss = {test_loss}')\n",
        "print(f'Accuracy = {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "OhLW4u95xDbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = pf_test.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch)\n",
        "class_predictions = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "hwJAJBkYxFe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Show some prediction results\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(4):\n",
        "    axs = plt.subplot(2,2,i+1)\n",
        "    plt.imshow(image_batch[i].astype('uint8'))\n",
        "    current_prediction = class_names[class_predictions[i]]\n",
        "    current_label = class_names[label_batch[i]]\n",
        "    plt.title(f\"Prediction: {current_prediction}, Actual: {current_label}\")\n",
        "    plt.axis('off')\n",
        "    \n",
        "save_path = r\"\"\n",
        "plt.savefig(os.path.join(save_path,\"result.png\"),bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "#%%\n",
        "from numba import cuda \n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "yXjbUhpOxHIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}